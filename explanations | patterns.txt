********** PROBLEM WRITEUPS **********

WRITEUPS:

18: 4sum.js has a good writeup on using `continue` / while loops
53: Maximum Subarray.js explains why we can reset the left wall of kadane's fully, instead of just doing l++
209: Minimum Size Subarray.js showcases how we decrement from l as much as possible until our constraint fails
907: Sum of Subarray Minimums. There are n^2 subarrays, we can compute all their minimums while still in n^2, because we can do something like the following, where we memoize the minimum value for that subarray. BUT there is a linear method.
for (...) {
  let min = Infinity
  for (...) {
    min = ...
  }
}
76: Minimum Window Substring has a good writeup on managing desirability and undesirability of variable sliding windows
240: Search a 2D Matrix II (in binary) has a good writeup on thinking about pivot points and recognizing that you should use pivots in things with sorted properties
380: Insert Delete GetRandomO(1) and 706: Design Hashmap have good writeups on using hash tables, linear probing, etc.
234: Palindrome Linked List has a good writeup on reversing a portion of a linked list and not severing a connection





********** ANAGRAMS **********

Problem: 483 / 567
Matching character frequencies, we can use a have and a need counter and increment and decrement when needed.





********** TREES / BST **********
104: Maximum Depth of Binary Tree has good writeups on using different searches in very elegant ways.

In problem 543: Diameter of Binary tree, there are a few ways to solve it.
1) bottom up recursion (n), so go down to the bottom, then use the base case results to form something meaningful, update the result if needed, and return the diameter up one level.
2) top down with no memoization (n^2). Iterate through the tree, for each node, solve it's diameter.
3) top down with caching (n). Iterate through the tree, caching the max depth that node can reach. So at a root:
    5
   / \
  1   3
We solve for 5, meaning we recurse / solve for the depths of its children. When the children reach the base case, they terminate. Since we are no longer recursing down, we finally start to solve for the max depths based on the biggest of the children. We set this in the cache, then bubble back up the result.
Then, we do a dfs through each node, checking the max depths of its children, and updating the result.

This was really poorly designed for a couple reasons though! We're already getting the left and right depths at the nodes, we have basically already written the bottom up recursive function. We may as well just update the result there.

I think we could have done it in one funciton too, instead of filling the cache with one function, then iterating through and updating the result with another. It ends up being more confusing and just a worse version of the bottom up recursion though, I feel.

Problem 530 has a successful bottom up recursion (though inorder traversal solution is even nicer). The idea is for each node we need to know the smallest and largest value in its tree. Instead of trying to run two functions, we just track both within the same function, using a tuple. We recurse down to the bottom, the bubble up results.



Inorder traversal will print out a BST in ascending order. We can use this to find the kth largest element or kth smallest element (problem 230)

Inorder, Preorder, Postorder iterative traversals should be reviewed

To construct a tree from the pre and inorder traversals, assuming values are unique, use recursion. The first element of preorder will determine the root, and the inorder array will determine how many elements go into the left child, and how many into the right.

TODO: delete a node in BST

In a BST, we can figure out the neighbors of a value, by looking at the largest values in the left subtree, and the smallest in the right. For instance:

    15
   /  \
  12  20
   \
   14

  To find the largest number smaller than 15, we look at the max in left subtree. To find smallest number that is larger than 20, we find the smallest number in the right subtree. The result would not be the parent of 10, because that is always smaller than elements in the left subtree. However, if the element doesn't have a left subtree, then the left neighbor would be its parent.

  We could do this by iterating through the tree, tracking the largest smaller and smallest larger numbers, terminating when we finish the tree.

  We can also do other valuable things that require a sorted structure, such as finding the minimum, maximum, and range queries (find all elements between x and y) in log n time (except for the range query, which is log n + k, and requires recursing down the bst and pruning). We can also find the largest number that is smaller than n, by traversing the tree. I think it is useful to just think of it as similar to a sorted list, except insertion and deletion are faster, and we don't have O(1) to the nth biggest number. We can find the nth biggest number in O(log n) if each node contains info for the number of nodes in its subtree, including itself.


To check if a tree contains another subtree, we can serialize them and use string matching. Or we can do a full subtree check on each treenode.

A preorder traversal with null nodes always uniquely serializes a tree. Postorder should as well. Proof: https://cs.stackexchange.com/questions/116655/which-tree-traversal-string-is-unique

Inorder does not:

    0
   /
  0

  and

  0
   \
    0

  Both serialize to null, 0, null, 0, null, when using inorder.

Often in trees, we have some recursive function like trimBST, that returns a trimmed version or some modified version of a tree. We can use this itself as the recursive function, and assign our left and right pointers to be the modified versions too, like in problem 669: Trim a Binary Search Tree.

To see a serialization and deserialization with just preorder traversal, see problem 297: Serialize and Deserialize Binary Tree.

A preorder + postorder (without nulls) traversal does not uniquely serialize.
For instance:  1       and          1
                \                  /
                 2                2

Both have pre: 1, 2 and post: 2, 1 traversals.

in a bst we could find the midpoint element in log n time if we knew the size of the left and right subtrees.

Problem 98 and 783 show good ways to do inorder on BST and not need an array to track all the values (for finding if the BST is valid, minimum difference between nodes, etc).


We can always maintain a global variable, such as 'prev', when doing something like an inorder traversal. For instance in 426: Convert BST to sorted doubly linked list, we just do an inorder traversal, but store what the previous node was.

********** AVL TREE **********

A self balancing binary tree works by doing rotations, where we rotate around x and y and rearrange subtrees. Sometimes a more complex rotation is needed as the basic rotation does not balance the tree.



********** SQUARE ROOT DECOMP **********
If we don't have a perfect square number of elements, it is common to take the ceiling of the root for the chunk size, but both floor and ceiling work.

307: Range Sum Query - Mutable shows how we can use square root decomp to mutate variables in an array and still have fast queries.

Say we need to implement a big string class, for like 500k+ characters, and we want to support insert and remove at arbitrary indices. Naive would require shifting each character for each operation. What we could do is square root decomp, so we store root n deques, and now when we need to insert, we look up which deque to insert it in. Then we just do a root n time operation to insert it into the middle of the deque. Chatgpt: If a block's size exceeds 2√n after insertion, split it into two blocks each of size approximately √n. If a block's size drops below √n/2 after deletion, merge it with an adjacent block and then possibly split the merged block if its size exceeds 2√n.
But why not just split it into n chunks? Because then each time we add something, we might overflow and need to create a new chunk or reallocate memory for a chunk. If we allocated n chunks, but extra memory in each chunk, that could work, but then when we fill up that memory we need to reallocate, so I'm not actually sure if that ends up being any better.

********** AVL TREES VS HEAPS **********

AVL trees support add (log n), remove (log n), and search (log n). We can also support min and max in constant time. Maintain a pointer to the smallest element, and each element maintains a pointer to the element just bigger than it. AVL trees can also tell you how many elements are bigger or smaller than a given number in log n time, it takes log n time to find that number (or if it isn't there, where it would be, I am assuming), then constant time to find how many are bigger or smaller than it, if we maintain additional bookkeeping.

Heaps support add (log n), remove (log n), and min/max in constant time. However, heaps are faster under the hood, practically, because they use arrays. AVL trees cannot forcibly be complete (I think), whereas heaps are complete and therefore can use arrays.


********** GENERAL TIPS **********

If your code isn't working at all (but your solution is close, just debugging), instead of walking through a complicated test case, if no easy ones are given, try manually using an easy test case.

********** MISC **********

Hashing a string of length n is an O(n) operation, so doing a set lookup on a string depends on the length of that string.

********** TODOS **********

2244: minimum rounds to complete all tasks, use a better solution
// TODO: find sum of all subarrays also for any array
add explanation for problem w95 substring 26nle
leetcode add solutions for contest problems, and one c++ submission i accidentally sent i need to do, same with trapping rainwater2
delete node in bst by reference not by overwriting value
todo: eventually redo construct binary tree from preorder and postorder traversal
// todo: add assesement questions and contest questions
// update all guides to be simplfiied, readable anew, have example problems that illustrate things, do 1 a day maybe
// learn bit
https://cs.stackexchange.com/questions/10538/bit-what-is-the-intuition-behind-a-binary-indexed-tree-and-how-was-it-thought-a

learn avl tree


mini processed:
binary search

processed:
sorting


********** TODO PROBLEMS **********

finished this but submit solution when done with graphs:
863: same
802: same
https://leetcode.com/problems/find-eventual-safe-states/description/

TODO PROPERLY:
65: learn DFA solution, I solved normally already: https://leetcode.com/problems/valid-number/
1489: https://leetcode.com/problems/find-critical-and-pseudo-critical-edges-in-minimum-spanning-tree/description/
168: https://leetcode.com/problems/excel-sheet-column-title/description/
1203: https://leetcode.com/problems/sort-items-by-groups-respecting-dependencies/
1183: https://leetcode.com/problems/maximum-number-of-ones/description/
145: https://leetcode.com/problems/binary-tree-postorder-traversal/description/
2009: https://leetcode.com/problems/minimum-number-of-operations-to-make-array-continuous/description/?envType=daily-question&envId=2023-10-10
using iterative
1063: https://leetcode.com/problems/number-of-valid-subarrays/description/
redo stack solution
847: https://leetcode.com/problems/shortest-path-visiting-all-nodes/?envType=daily-question&envId=2023-09-17
learn the infinity cache trick PROPERLY
I think this can also use the infinity cache trick: https://leetcode.com/problems/minimum-cost-to-buy-apples/
880: https://leetcode.com/problems/decoded-string-at-index/description/
930: https://leetcode.com/problems/binary-subarrays-with-sum/description/
229: https://leetcode.com/problems/majority-element-ii/description/
1048: https://leetcode.com/problems/longest-string-chain/
2355: https://leetcode.com/problems/maximum-number-of-books-you-can-take/
341: https://leetcode.com/problems/flatten-nested-list-iterator/description/
1793: https://leetcode.com/problems/maximum-score-of-a-good-subarray/
1361: https://leetcode.com/problems/validate-binary-tree-nodes/
382: https://leetcode.com/problems/linked-list-random-node/
learn reservoir smapling
2050: https://leetcode.com/problems/parallel-courses-iii/description/
1425: https://leetcode.com/problems/constrained-subsequence-sum/description/
779: https://leetcode.com/problems/k-th-symbol-in-grammar/description/
823: https://leetcode.com/problems/binary-trees-with-factors/description/
1660: https://leetcode.com/problems/correct-a-binary-tree/description/
458: https://leetcode.com/problems/poor-pigs/description/
1535: https://leetcode.com/problems/find-the-winner-of-an-array-game/
2642: https://leetcode.com/problems/design-graph-with-shortest-path-calculator/description/
1611: https://leetcode.com/problems/minimum-one-bit-operations-to-make-integers-zero/description/

TODO:
reason why binary lift max jump needs to be LOG floor, is it just one edge case with n=1?
get space efficient segment tree understanding

TODO:
djikstras time, FW time, normal bfs and dfs, read dfs time from editorial: https://leetcode.com/problems/network-delay-time/description/ and djikstra time
also get more FW experience, understand which conditions it can be used, look at more patterns like the trick lee did to reuse array, etc
TODO: find shortest from one node to all others, djikstra, bfs? repeat that subroutine for all nodes instead of using FW for contest problem
todo: add larry bitmask trick for 1 << n iterate subsets
TODO: numb3r5 method for intervals from left to right, and his interval merging alg
todo: rjmc comment about djikstras